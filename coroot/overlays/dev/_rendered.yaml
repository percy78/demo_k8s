apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: coroot
    app.kubernetes.io/version: 0.18.1
    helm.sh/chart: coroot-0.3.11
  name: coroot
  namespace: coroot
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: clickhouse
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: clickhouse
    helm.sh/chart: clickhouse-3.1.6
  name: coroot-clickhouse
  namespace: coroot
---
apiVersion: v1
imagePullSecrets: []
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: metrics
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/version: 2.5.0
    helm.sh/chart: kube-state-metrics-4.13.0
  name: coroot-kube-state-metrics
  namespace: coroot
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/version: 0.75.0
    helm.sh/chart: opentelemetry-collector-0.52.1
  name: coroot-opentelemetry-collector
  namespace: coroot
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: prometheus
    chart: prometheus-15.16.1
    component: server
    heritage: Helm
    release: coroot
  name: coroot-prometheus-server
  namespace: coroot
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-0.2.92
  name: coroot-pyroscope
  namespace: coroot
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope-ebpf
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-ebpf-0.1.31
    name: pyroscope-ebpf
  name: coroot-pyroscope-ebpf
  namespace: coroot
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope-ebpf
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-ebpf-0.1.31
    name: pyroscope-ebpf
  name: coroot-pyroscope-ebpf
  namespace: coroot
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  - pods
  verbs:
  - get
  - list
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: metrics
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/version: 2.5.0
    helm.sh/chart: kube-state-metrics-4.13.0
  name: coroot-kube-state-metrics
rules:
- apiGroups:
  - certificates.k8s.io
  resources:
  - certificatesigningrequests
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - list
  - watch
- apiGroups:
  - batch
  resources:
  - cronjobs
  verbs:
  - list
  - watch
- apiGroups:
  - extensions
  - apps
  resources:
  - daemonsets
  verbs:
  - list
  - watch
- apiGroups:
  - extensions
  - apps
  resources:
  - deployments
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - list
  - watch
- apiGroups:
  - autoscaling
  resources:
  - horizontalpodautoscalers
  verbs:
  - list
  - watch
- apiGroups:
  - extensions
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - list
  - watch
- apiGroups:
  - batch
  resources:
  - jobs
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - limitranges
  verbs:
  - list
  - watch
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - namespaces
  verbs:
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - networkpolicies
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  verbs:
  - list
  - watch
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - list
  - watch
- apiGroups:
  - extensions
  - apps
  resources:
  - replicasets
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - replicationcontrollers
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - resourcequotas
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - statefulsets
  verbs:
  - list
  - watch
- apiGroups:
  - storage.k8s.io
  resources:
  - storageclasses
  verbs:
  - list
  - watch
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - validatingwebhookconfigurations
  verbs:
  - list
  - watch
- apiGroups:
  - storage.k8s.io
  resources:
  - volumeattachments
  verbs:
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: prometheus
    chart: prometheus-15.16.1
    component: server
    heritage: Helm
    release: coroot
  name: coroot-prometheus-server
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  - nodes/proxy
  - nodes/metrics
  - services
  - endpoints
  - pods
  - ingresses
  - configmaps
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  - networking.k8s.io
  resources:
  - ingresses/status
  - ingresses
  verbs:
  - get
  - list
  - watch
- nonResourceURLs:
  - /metrics
  verbs:
  - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-0.2.92
  name: coroot-pyroscope
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  - services
  - endpoints
  - pods
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope-ebpf
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-ebpf-0.1.31
    name: pyroscope-ebpf
  name: coroot-pyroscope-ebpf
  namespace: coroot
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: coroot-pyroscope-ebpf
subjects:
- kind: ServiceAccount
  name: coroot-pyroscope-ebpf
  namespace: coroot
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: metrics
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/version: 2.5.0
    helm.sh/chart: kube-state-metrics-4.13.0
  name: coroot-kube-state-metrics
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: coroot-kube-state-metrics
subjects:
- kind: ServiceAccount
  name: coroot-kube-state-metrics
  namespace: coroot
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: prometheus
    chart: prometheus-15.16.1
    component: server
    heritage: Helm
    release: coroot
  name: coroot-prometheus-server
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: coroot-prometheus-server
subjects:
- kind: ServiceAccount
  name: coroot-prometheus-server
  namespace: coroot
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-0.2.92
  name: coroot-pyroscope
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: coroot-pyroscope
subjects:
- kind: ServiceAccount
  name: coroot-pyroscope
  namespace: coroot
---
apiVersion: v1
data:
  00_default_overrides.xml: |
    <clickhouse>
      <!-- Macros -->
      <macros>
        <shard from_env="CLICKHOUSE_SHARD_ID"></shard>
        <replica from_env="CLICKHOUSE_REPLICA_ID"></replica>
        <layer>coroot-clickhouse</layer>
      </macros>
      <!-- Log Level -->
      <logger>
        <level>information</level>
      </logger>
    </clickhouse>
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: clickhouse
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: clickhouse
    helm.sh/chart: clickhouse-3.1.6
  name: coroot-clickhouse
  namespace: coroot
---
apiVersion: v1
data:
  setup.sh: |-
    #!/bin/bash

    # Execute entrypoint as usual after obtaining KEEPER_SERVER_ID
    # check KEEPER_SERVER_ID in persistent volume via myid
    # if not present, set based on POD hostname
    if [[ -f "/bitnami/clickhouse/keeper/data/myid" ]]; then
        export KEEPER_SERVER_ID="$(cat /bitnami/clickhouse/keeper/data/myid)"
    else
        HOSTNAME="$(hostname -s)"
        if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
            export KEEPER_SERVER_ID=${BASH_REMATCH[2]}
        else
            echo "Failed to get index from hostname $HOST"
            exit 1
        fi
    fi
    exec /opt/bitnami/scripts/clickhouse/entrypoint.sh /opt/bitnami/scripts/clickhouse/run.sh -- --listen_host=0.0.0.0
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: clickhouse
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: clickhouse
    helm.sh/chart: clickhouse-3.1.6
  name: coroot-clickhouse-scripts
  namespace: coroot
---
apiVersion: v1
data:
  relay: |
    exporters:
      clickhouse:
        database: default
        endpoint: tcp://coroot-clickhouse:9000?dial_timeout=10s&compress=lz4
        logs_table_name: otel_logs
        metrics_table_name: otel_metrics
        password: ${env:CLICKHOUSE_PASSWORD}
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_elapsed_time: 300s
          max_interval: 30s
        timeout: 5s
        traces_table_name: otel_traces
        ttl_days: 7
        username: default
      logging: {}
    extensions:
      health_check: {}
      memory_ballast:
        size_in_percentage: 40
    processors:
      batch:
        send_batch_size: 100000
        timeout: 5s
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
    receivers:
      jaeger:
        protocols:
          grpc:
            endpoint: ${MY_POD_IP}:14250
          thrift_compact:
            endpoint: ${MY_POD_IP}:6831
          thrift_http:
            endpoint: ${MY_POD_IP}:14268
      otlp:
        protocols:
          grpc:
            endpoint: ${MY_POD_IP}:4317
          http:
            endpoint: ${MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
            - targets:
              - ${MY_POD_IP}:8888
      zipkin:
        endpoint: ${MY_POD_IP}:9411
    service:
      extensions:
      - health_check
      - memory_ballast
      pipelines:
        logs:
          exporters:
          - logging
          processors:
          - memory_limiter
          - batch
          receivers:
          - otlp
        metrics:
          exporters:
          - logging
          processors:
          - memory_limiter
          - batch
          receivers:
          - otlp
          - prometheus
        traces:
          exporters:
          - clickhouse
          processors:
          - batch
          receivers:
          - otlp
      telemetry:
        metrics:
          address: ${MY_POD_IP}:8888
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/version: 0.75.0
    helm.sh/chart: opentelemetry-collector-0.52.1
  name: coroot-opentelemetry-collector
  namespace: coroot
---
apiVersion: v1
data:
  alerting_rules.yml: |
    {}
  alerts: |
    {}
  allow-snippet-annotations: "false"
  prometheus.yml: |
    global:
      evaluation_interval: 1m
      scrape_interval: 15s
      scrape_timeout: 10s
    rule_files:
    - /etc/config/recording_rules.yml
    - /etc/config/alerting_rules.yml
    - /etc/config/rules
    - /etc/config/alerts
    scrape_configs:
    - job_name: prometheus
      static_configs:
      - targets:
        - localhost:9090
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-apiservers
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: default;kubernetes;https
        source_labels:
        - __meta_kubernetes_namespace
        - __meta_kubernetes_service_name
        - __meta_kubernetes_endpoint_port_name
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes-cadvisor
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - honor_labels: true
      job_name: kubernetes-service-endpoints
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape
      - action: drop
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: (.+?)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
        replacement: __param_$1
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: service
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: node
    - honor_labels: true
      job_name: kubernetes-service-endpoints-slow
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: (.+?)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
        replacement: __param_$1
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: service
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: node
      scrape_interval: 5m
      scrape_timeout: 30s
    - honor_labels: true
      job_name: prometheus-pushgateway
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - action: keep
        regex: pushgateway
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
    - honor_labels: true
      job_name: kubernetes-services
      kubernetes_sd_configs:
      - role: service
      metrics_path: /probe
      params:
        module:
        - http_2xx
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
      - source_labels:
        - __address__
        target_label: __param_target
      - replacement: blackbox
        target_label: __address__
      - source_labels:
        - __param_target
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - source_labels:
        - __meta_kubernetes_service_name
        target_label: service
    - honor_labels: true
      job_name: kubernetes-pods
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape
      - action: drop
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: (.+?)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
        replacement: __param_$1
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: pod
      - action: drop
        regex: Pending|Succeeded|Failed|Completed
        source_labels:
        - __meta_kubernetes_pod_phase
    - honor_labels: true
      job_name: kubernetes-pods-slow
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: (.+?)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
        replacement: __param_$1
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: pod
      - action: drop
        regex: Pending|Succeeded|Failed|Completed
        source_labels:
        - __meta_kubernetes_pod_phase
      scrape_interval: 5m
      scrape_timeout: 30s
  recording_rules.yml: |
    {}
  rules: |
    {}
kind: ConfigMap
metadata:
  labels:
    app: prometheus
    chart: prometheus-15.16.1
    component: server
    heritage: Helm
    release: coroot
  name: coroot-prometheus-server
  namespace: coroot
---
apiVersion: v1
data:
  config.yaml: |
    log-level: debug
    retention: 8h
    retention-levels:
      "0": 1h
      "1": 4h
      "2": 8h
    scrape-configs:
    - enabled-profiles:
      - cpu
      - mem
      job-name: kubernetes-pods
      kubernetes-sd-configs:
      - role: pod
      relabel-configs:
      - action: keep
        regex: true
        source-labels:
        - __meta_kubernetes_pod_annotation_pyroscope_io_scrape
      - action: replace
        source-labels:
        - __meta_kubernetes_pod_annotation_pyroscope_io_application_name
        target-label: __name__
      - action: replace
        regex: (https?)
        source-labels:
        - __meta_kubernetes_pod_annotation_pyroscope_io_scheme
        target-label: __scheme__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source-labels:
        - __address__
        - __meta_kubernetes_pod_annotation_pyroscope_io_port
        target-label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source-labels:
        - __meta_kubernetes_namespace
        target-label: namespace
      - action: replace
        source-labels:
        - __meta_kubernetes_pod_name
        target-label: pod
      - action: drop
        regex: Pending|Succeeded|Failed|Completed
        source-labels:
        - __meta_kubernetes_pod_phase
      - action: labelmap
        regex: __meta_kubernetes_pod_annotation_pyroscope_io_profile_(.+)
        replacement: __profile_$1
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-0.2.92
  name: coroot-pyroscope
  namespace: coroot
---
apiVersion: v1
data:
  admin-password: aXlja2QwRlhqMA==
kind: Secret
metadata:
  labels:
    app.kubernetes.io/component: clickhouse
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: clickhouse
    helm.sh/chart: clickhouse-3.1.6
  name: coroot-clickhouse
  namespace: coroot
type: Opaque
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: coroot
    app.kubernetes.io/version: 0.18.1
    helm.sh/chart: coroot-0.3.11
  name: coroot
  namespace: coroot
spec:
  ports:
  - name: http
    port: 8080
    protocol: TCP
    targetPort: http
  selector:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/name: coroot
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: clickhouse
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: clickhouse
    helm.sh/chart: clickhouse-3.1.6
  name: coroot-clickhouse
  namespace: coroot
spec:
  ports:
  - name: http
    nodePort: null
    port: 8123
    protocol: TCP
    targetPort: http
  - name: tcp
    nodePort: null
    port: 9000
    protocol: TCP
    targetPort: tcp
  - name: tcp-mysql
    nodePort: null
    port: 9004
    protocol: TCP
    targetPort: tcp-mysql
  - name: tcp-postgresql
    nodePort: null
    port: 9005
    protocol: TCP
    targetPort: tcp-postgresql
  - name: http-intersrv
    nodePort: null
    port: 9009
    protocol: TCP
    targetPort: http-intersrv
  selector:
    app.kubernetes.io/component: clickhouse
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/name: clickhouse
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: clickhouse
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: clickhouse
    helm.sh/chart: clickhouse-3.1.6
  name: coroot-clickhouse-headless
  namespace: coroot
spec:
  clusterIP: None
  ports:
  - name: http
    port: 8123
    protocol: TCP
    targetPort: http
  - name: tcp
    port: 9000
    protocol: TCP
    targetPort: tcp
  - name: tcp-mysql
    port: 9004
    protocol: TCP
    targetPort: tcp-mysql
  - name: tcp-postgresql
    port: 9005
    protocol: TCP
    targetPort: tcp-postgresql
  - name: http-intersrv
    port: 9009
    protocol: TCP
    targetPort: http-intersrv
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: clickhouse
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/name: clickhouse
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "true"
  labels:
    app.kubernetes.io/component: metrics
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/version: 2.5.0
    helm.sh/chart: kube-state-metrics-4.13.0
  name: coroot-kube-state-metrics
  namespace: coroot
spec:
  ports:
  - name: http
    port: 8080
    protocol: TCP
    targetPort: 8080
  selector:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/name: kube-state-metrics
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/version: 0.75.0
    component: standalone-collector
    helm.sh/chart: opentelemetry-collector-0.52.1
  name: coroot-opentelemetry-collector
  namespace: coroot
spec:
  ports:
  - appProtocol: grpc
    name: otlp
    port: 4317
    protocol: TCP
    targetPort: 4317
  - name: otlp-http
    port: 4318
    protocol: TCP
    targetPort: 4318
  selector:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/name: opentelemetry-collector
    component: standalone-collector
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: prometheus
    chart: prometheus-15.16.1
    component: server
    heritage: Helm
    release: coroot
  name: coroot-prometheus-server
  namespace: coroot
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 9090
  selector:
    app: prometheus
    component: server
    release: coroot
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-0.2.92
  name: coroot-pyroscope
  namespace: coroot
spec:
  ports:
  - name: http
    port: 4040
    protocol: TCP
    targetPort: api
  selector:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/name: pyroscope
  type: ClusterIP
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: coroot
    app.kubernetes.io/version: 0.18.1
    helm.sh/chart: coroot-0.3.11
  name: coroot-data
  namespace: coroot
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: longhorn
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  labels:
    app: prometheus
    chart: prometheus-15.16.1
    component: server
    heritage: Helm
    release: coroot
  name: coroot-prometheus-server
  namespace: coroot
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  finalizers:
  - kubernetes.io/pvc-protection
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-0.2.92
  name: coroot-pyroscope
  namespace: coroot
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 30Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: coroot
    app.kubernetes.io/version: 0.18.1
    helm.sh/chart: coroot-0.3.11
  name: coroot
  namespace: coroot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: coroot
      app.kubernetes.io/name: coroot
  strategy:
    rollingUpdate:
      maxSurge: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: coroot
        app.kubernetes.io/name: coroot
    spec:
      containers:
      - args:
        - --listen=:8080
        - --data-dir=/data
        - --bootstrap-prometheus-url=http://coroot-prometheus-server:80
        - --bootstrap-refresh-interval=15s
        env:
        - name: BOOTSTRAP_PYROSCOPE_URL
          value: http://coroot-pyroscope:4040
        - name: BOOTSTRAP_CLICKHOUSE_ADDRESS
          value: coroot-clickhouse:9000
        - name: BOOTSTRAP_CLICKHOUSE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: admin-password
              name: coroot-clickhouse
        - name: BOOTSTRAP_CLICKHOUSE_USER
          value: default
        - name: BOOTSTRAP_CLICKHOUSE_DATABASE
          value: default
        - name: BOOTSTRAP_CLICKHOUSE_TRACES_TABLE
          value: otel_traces
        image: ghcr.io/coroot/coroot:0.18.1
        imagePullPolicy: IfNotPresent
        name: coroot
        ports:
        - containerPort: 8080
          name: http
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /health
            port: http
        resources:
          requests:
            cpu: 100m
            memory: 1Gi
        securityContext: {}
        volumeMounts:
        - mountPath: /data
          name: data
      securityContext: {}
      serviceAccountName: coroot
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: coroot-data
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: metrics
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/version: 2.5.0
    helm.sh/chart: kube-state-metrics-4.13.0
  name: coroot-kube-state-metrics
  namespace: coroot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: coroot
      app.kubernetes.io/name: kube-state-metrics
  template:
    metadata:
      labels:
        app.kubernetes.io/component: metrics
        app.kubernetes.io/instance: coroot
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/part-of: kube-state-metrics
        app.kubernetes.io/version: 2.5.0
        helm.sh/chart: kube-state-metrics-4.13.0
    spec:
      containers:
      - args:
        - --port=8080
        - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
        - --metric-labels-allowlist=pods=[*]
        - --telemetry-port=8081
        image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.5.0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 5
          timeoutSeconds: 5
        name: kube-state-metrics
        ports:
        - containerPort: 8080
          name: http
        readinessProbe:
          httpGet:
            path: /
            port: 8080
          initialDelaySeconds: 5
          timeoutSeconds: 5
      hostNetwork: false
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsUser: 65534
      serviceAccountName: coroot-kube-state-metrics
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/version: 0.75.0
    helm.sh/chart: opentelemetry-collector-0.52.1
  name: coroot-opentelemetry-collector
  namespace: coroot
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: coroot
      app.kubernetes.io/name: opentelemetry-collector
      component: standalone-collector
  strategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: 1944696c3dd5bc8be89ae6701bd8519f8875610338eaa7778bf18cf8c5b43f61
      labels:
        app.kubernetes.io/instance: coroot
        app.kubernetes.io/name: opentelemetry-collector
        component: standalone-collector
    spec:
      containers:
      - command:
        - /otelcol-contrib
        - --config=/conf/relay.yaml
        env:
        - name: MY_POD_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        - name: CLICKHOUSE_PASSWORD
          valueFrom:
            secretKeyRef:
              key: admin-password
              name: coroot-clickhouse
        image: otel/opentelemetry-collector-contrib:0.75.0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /
            port: 13133
        name: opentelemetry-collector
        ports:
        - containerPort: 4317
          name: otlp
          protocol: TCP
        - containerPort: 4318
          name: otlp-http
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /
            port: 13133
        resources:
          limits:
            cpu: 256m
            memory: 512Mi
        securityContext: {}
        volumeMounts:
        - mountPath: /conf
          name: opentelemetry-collector-configmap
      hostNetwork: false
      securityContext: {}
      serviceAccountName: coroot-opentelemetry-collector
      volumes:
      - configMap:
          items:
          - key: relay
            path: relay.yaml
          name: coroot-opentelemetry-collector
        name: opentelemetry-collector-configmap
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: prometheus
    chart: prometheus-15.16.1
    component: server
    heritage: Helm
    release: coroot
  name: coroot-prometheus-server
  namespace: coroot
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
      component: server
      release: coroot
  template:
    metadata:
      labels:
        app: prometheus
        chart: prometheus-15.16.1
        component: server
        heritage: Helm
        release: coroot
    spec:
      containers:
      - args:
        - --volume-dir=/etc/config
        - --webhook-url=http://127.0.0.1:9090/-/reload
        image: jimmidyson/configmap-reload:v0.5.0
        imagePullPolicy: IfNotPresent
        name: prometheus-server-configmap-reload
        resources: {}
        securityContext: {}
        volumeMounts:
        - mountPath: /etc/config
          name: config-volume
          readOnly: true
      - args:
        - --storage.tsdb.retention.time=1d
        - --config.file=/etc/config/prometheus.yml
        - --storage.tsdb.path=/data
        - --web.console.libraries=/etc/prometheus/console_libraries
        - --web.console.templates=/etc/prometheus/consoles
        - --web.enable-lifecycle
        image: quay.io/prometheus/prometheus:v2.39.1
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /-/healthy
            port: 9090
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 10
        name: prometheus-server
        ports:
        - containerPort: 9090
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /-/ready
            port: 9090
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 4
        resources: {}
        volumeMounts:
        - mountPath: /etc/config
          name: config-volume
        - mountPath: /data
          name: storage-volume
          subPath: ""
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      serviceAccountName: coroot-prometheus-server
      terminationGracePeriodSeconds: 300
      volumes:
      - configMap:
          name: coroot-prometheus-server
        name: config-volume
      - name: storage-volume
        persistentVolumeClaim:
          claimName: coroot-prometheus-server
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-0.2.92
  name: coroot-pyroscope
  namespace: coroot
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: coroot
      app.kubernetes.io/name: pyroscope
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        checksum/config: 550489f848eaa5eb885de439b98d7d8dbb56909a71caa6c27280fcc9b4b8bd7a
      labels:
        app.kubernetes.io/instance: coroot
        app.kubernetes.io/name: pyroscope
    spec:
      containers:
      - args:
        - server
        - -config
        - /tmp/config.yaml
        image: pyroscope/pyroscope:0.37.2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 4040
          initialDelaySeconds: 30
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 30
        name: pyroscope
        ports:
        - containerPort: 4040
          name: api
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 4040
          initialDelaySeconds: 30
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 30
        resources: {}
        securityContext: {}
        volumeMounts:
        - mountPath: /tmp/config.yaml
          name: config
          subPath: config.yaml
        - mountPath: /var/lib/pyroscope
          name: storage
      securityContext:
        fsGroup: 101
      serviceAccountName: coroot-pyroscope
      volumes:
      - configMap:
          name: coroot-pyroscope
        name: config
      - name: storage
        persistentVolumeClaim:
          claimName: coroot-pyroscope
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: clickhouse
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: clickhouse
    helm.sh/chart: clickhouse-3.1.6
  name: coroot-clickhouse-shard0
  namespace: coroot
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: clickhouse
      app.kubernetes.io/instance: coroot
      app.kubernetes.io/name: clickhouse
  serviceName: coroot-clickhouse-headless
  template:
    metadata:
      annotations:
        checksum/config: 7e7cb279be4cca0d087d13ab75912b829bf8b3e93ecc452bcda7632233c945bd
        checksum/config-extra: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
      labels:
        app.kubernetes.io/component: clickhouse
        app.kubernetes.io/instance: coroot
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: clickhouse
        helm.sh/chart: clickhouse-3.1.6
    spec:
      affinity:
        nodeAffinity: null
        podAffinity: null
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: clickhouse
                  app.kubernetes.io/instance: coroot
                  app.kubernetes.io/name: clickhouse
              topologyKey: kubernetes.io/hostname
            weight: 1
      containers:
      - command:
        - /scripts/setup.sh
        env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: CLICKHOUSE_HTTP_PORT
          value: "8123"
        - name: CLICKHOUSE_TCP_PORT
          value: "9000"
        - name: CLICKHOUSE_MYSQL_PORT
          value: "9004"
        - name: CLICKHOUSE_POSTGRESQL_PORT
          value: "9005"
        - name: CLICKHOUSE_INTERSERVER_HTTP_PORT
          value: "9009"
        - name: CLICKHOUSE_ADMIN_USER
          value: default
        - name: CLICKHOUSE_SHARD_ID
          value: shard0
        - name: CLICKHOUSE_REPLICA_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: CLICKHOUSE_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              key: admin-password
              name: coroot-clickhouse
        envFrom: null
        image: docker.io/bitnami/clickhouse:23.3.1-debian-11-r0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /ping
            port: http
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        name: clickhouse
        ports:
        - containerPort: 8123
          name: http
        - containerPort: 9000
          name: tcp
        - containerPort: 9005
          name: tcp-postgresql
        - containerPort: 9004
          name: tcp-mysql
        - containerPort: 9009
          name: http-intersrv
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /ping
            port: http
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits: {}
          requests: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1001
        volumeMounts:
        - mountPath: /scripts/setup.sh
          name: scripts
          subPath: setup.sh
        - mountPath: /bitnami/clickhouse
          name: data
        - mountPath: /bitnami/clickhouse/etc/conf.d/default
          name: config
      initContainers: null
      securityContext:
        fsGroup: 1001
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: coroot-clickhouse
      volumes:
      - configMap:
          defaultMode: 493
          name: coroot-clickhouse-scripts
        name: scripts
      - configMap:
          name: coroot-clickhouse
        name: config
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      annotations: null
      labels:
        app.kubernetes.io/component: clickhouse
        app.kubernetes.io/instance: coroot
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: clickhouse
        helm.sh/chart: clickhouse-3.1.6
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 50Gi
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: node-agent
    app.kubernetes.io/version: 1.11.0
    helm.sh/chart: node-agent-0.1.40
  name: coroot-node-agent
  namespace: coroot
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: coroot
      app.kubernetes.io/name: node-agent
  template:
    metadata:
      annotations:
        prometheus.io/port: "80"
        prometheus.io/scrape: "true"
      labels:
        app: coroot-node-agent
        app.kubernetes.io/instance: coroot
        app.kubernetes.io/name: node-agent
    spec:
      containers:
      - command:
        - coroot-node-agent
        - --cgroupfs-root
        - /host/sys/fs/cgroup
        env:
        - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
          value: http://coroot-opentelemetry-collector:4318/v1/traces
        image: ghcr.io/coroot/coroot-node-agent:1.11.0
        imagePullPolicy: IfNotPresent
        name: node-agent
        ports:
        - containerPort: 80
          name: http
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 50Mi
        securityContext:
          privileged: true
        volumeMounts:
        - mountPath: /host/sys/fs/cgroup
          name: cgroupfs
          readOnly: true
        - mountPath: /sys/kernel/debug
          name: debugfs
          readOnly: false
      hostPID: true
      priorityClassName: null
      tolerations:
      - operator: Exists
      volumes:
      - hostPath:
          path: /sys/fs/cgroup
        name: cgroupfs
      - hostPath:
          path: /sys/kernel/debug
        name: debugfs
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app.kubernetes.io/instance: coroot
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: pyroscope-ebpf
    app.kubernetes.io/version: 0.37.2
    helm.sh/chart: pyroscope-ebpf-0.1.31
    name: pyroscope-ebpf
  name: coroot-pyroscope-ebpf
  namespace: coroot
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: coroot
      app.kubernetes.io/name: pyroscope-ebpf
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: coroot
        app.kubernetes.io/name: pyroscope-ebpf
    spec:
      containers:
      - args:
        - ebpf
        - --application-name
        - k8s.ebpf
        - --server-address
        - http://coroot-pyroscope:4040
        env:
        - name: PYROSCOPE_KUBERNETES_NODE
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        image: pyroscope/pyroscope:0.37.2
        imagePullPolicy: IfNotPresent
        name: pyroscope-agent
        resources: {}
        securityContext:
          privileged: true
          runAsGroup: 0
          runAsUser: 0
      hostPID: true
      serviceAccountName: coroot-pyroscope-ebpf
      tolerations:
      - operator: Exists
